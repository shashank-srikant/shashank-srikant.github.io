---
layout: distill
title: From foe to friend\: Adversarial code assisted self-supervision co-improves robustness and generalization of code models
description: Can adversarial codes be used to improve the generalization and robustness of pre-trained code models? Yes.
date: 2022-01-10
tags: papers ml-for-plse program-representation minmax-optimization

---
<div class="publications">
    {% bibliography -f papers -q @*[key=srikant2022clawsat]* %}
</div>

## Abstract 
The self-supervised learning (SSL) paradigm, comprised of self-supervised representation pre-training and supervised fine-tuning, has shown encouraging improvements in the generalization of deep learning (DL) models trained on computer programs (code).
However, it is unclear how robust SSL models are against code obfuscation operations, and if there exists a way to co-optimize both generalization and robustness.
In this work, we investigate SSL (contrastive learning in particular) for code through the lens of adversarial robustness. 
First, at the self-supervised pre-training phase, we show that adversarial codes---codes generated using semantics-preserving obfuscations to fool code models---can serve as robustness-promoting views of code representation learning, yielding improved robustness and generalization for downstream tasks. 
Second, at the supervised fine-tuning stage, we show that 
adversarial training with a proper temporally-staggered schedule of adversarial code generation can further co-improve robustness and generalization.
Based on these insights, we propose ClawSAT, a novel SSL framework for code by integrating contrastive learning with adversarial  views (Claw) with staggered adversarial training (SAT).
On evaluating different code datasets in Python and Java for code summarization, we show that ClawSAT can yield substantial improvements, 11% in robustness and 6% in generalization, over baselines including the state-of-the-art method ContraCode (Jain et al., 2021).

## Links
### Under submission
