---
layout: default
title: shashank-srikant.github.io
description: Personal webpage of Shashank Srikant
---
<div class="row vertical-center about-desc">
	<div class="col-sm-12">
		<p class="lead" align="center"><h2>Research</h2></p>
	</div>
</div>	

<div class="row vertical-center about-desc">
	<div class="col-sm-5 paper">
		<iframe width="560" height="315" src="https://www.youtube.com/embed/vMlZwQZMwDs" frameborder="0" allowfullscreen></iframe>
	</div>
	<div class="col-sm-7 paper">
	  <h4>Aspiring Minds (Research group) <a href="http://research.aspiringminds.com" target="_blank">[link]</a></h4>
		   <p style="text-align:justify;">
		   Learning supervised models to grade open-ended responses is an expensive process. A model has to be trained for every prompt/question separately, which in turn requires graded samples. In automatic programming evaluation specically, the focus of this work, this issue is amplified. The models have to be trained not only for every question but also for every language the question is offered in. Moreover, the availability and time taken by experts to create a labeled set of programs for each question is a major bottleneck in scaling such a system. We address this issue by presenting a method to grade computer programs which requires no labeled samples for grading responses to a new, unseen question. We extend our previous work wherein we introduced a grammar of features to learn question specific models. In this work, we propose a method to transform those features into a set of features that maintain their structural relation with the labels across questions. Using these features we learn one supervised model across questions, which can then be applied to an ungraded response to an unseen question. We show that our method rivals the performance of both, question specific models and the consensus among human experts while substantially outperforming extant ways of evaluating codes. The learning from this work is transferable to other grading tasks such as math question grading and also provides a new variation to the supervised learning approach.
		   
		   <p><strong>Publications:</strong> KDD 2016, Plenary session presentation.</p> 
	</div>
</div>
